### 项目结构与执行方式分析

#### 1. `splite_data.py`（数据集分割）

**功能**：

- 将源数据集按指定比例（默认训练集 70%、验证集 15%、测试集 15%）分割为训练集、验证集和测试集，并复制到目标目录。
- 按类别目录组织文件，支持多类别图像数据集。
- 使用 `pathlib.Path` 确保跨平台兼容性。

**执行方式**：

```bash
python splite_data.py
```

**文件之间的关系**：

- 输出目录 `./data` 会被 `image_classification.py` 和 `image_prediction.py` 读取，用于训练和预测。
- 源目录 `./image_handle_class` 需要包含按类别组织的图像数据。

**需要修改的路径和参数**：

1. **路径**：
   - `source_directory = "./image_handle_class"`: 替换为实际的源数据集路径，例如 `r"D:\source\python\torch_big_data\Cyclone_Wildfire_Flood_Earthquake_Database"`。
   - `destination_directory = "./data"`: 确保目标路径存在且有写入权限，或者改为合适的路径，如 `r"D:\source\python\torch_big_data\data"`.
2. **参数**：
   - `train_ratio = 0.7`, `val_ratio = 0.15`: 可根据需求调整比例，但需确保 `train_ratio + val_ratio + test_ratio = 1`。
3. **建议**：
   - 检查源目录是否包含按类别组织的子目录（例如 `Cyclone`, `Wildfire` 等）。
   - 确保磁盘空间足够以复制文件。

---

#### 2. `image_processing.py`（图像预处理）

**功能**：

- 使用 Spark 读取 HDFS 或本地文件系统中的图像数据。
- 对图像进行预处理，包括：
  - 调整大小（随机缩放到 256-480 像素之间）
  - 归一化（减去通道均值）
  - 颜色抖动
  - 光照校正
  - 高斯滤波
  - 形态学操作（腐蚀和膨胀）
  - 小波去噪
- 保存处理后的图像到指定目录。

**执行方式**：

```bash
spark-submit image_processing.py
```

**文件之间的关系**：

- 输入路径 `hdfs_path` 指向原始数据集，可能与 `splite_data.py` 的 `source_directory` 相同。
- 输出目录 `./Wildfire` 可能用于后续训练或预测。
- 需要 Spark 环境支持。

**需要修改的路径和参数**：

1. **路径**：
   - `hdfs_path = r"D:\source\python\torch_big_data\Cyclone_Wildfire_Flood_Earthquake_Database\Wildfire"`: 替换为实际的 HDFS 路径或本地路径。如果不使用 HDFS，改为本地路径，如 `r"D:\source\python\torch_big_data\data\train\Wildfire"`.
   - `output_base_dir = Path("./Wildfire")`: 改为合适的输出路径，如 `r"D:\source\python\torch_big_data\processed_images\Wildfire"`.
2. **参数**：
   - `channel_means = np.array([123.68, 116.78, 103.94])`: 确保均值与数据集的实际分布一致（可能需要根据数据集重新计算）。
   - `batch_size = 100`: 可根据硬件性能调整，例如减少到 `50` 以降低内存占用。
3. **建议**：
   - 确保安装了 Spark 环境，并配置好 `pyspark`。
   - 检查 `pywt` 和 `cv2` 库是否安装。
   - 如果不使用 HDFS，可直接使用本地文件系统路径，并修改 `spark.read.format("binaryFile").load(hdfs_path)` 为本地路径读取。

---

#### 3. `image_classification.py`（模型训练与验证）

**功能**：

- 使用 ResNet18 模型进行图像分类训练。
- 创建训练和验证数据加载器（`DataLoader`），加载 `./data/train` 和 `./data/val` 的数据。
- 训练模型并验证性能，记录预测错误的图像并移动到指定目录。
- 保存训练好的模型。

**执行方式**：

```bash
python image_classification.py
```

**文件之间的关系**：

- 依赖 `splite_data.py` 生成的 `./data/train` 和 `./data/val` 目录。
- 错误图像移动到 `./source_lajidata`，可能用于后续分析。
- 保存的模型文件（如 `base_model_18_0.1_nolaji_source.pth`）被 `image_prediction.py` 使用。

**需要修改的路径和参数**：

1. **路径**：
   - `data_dir = "./data_source"`: 替换为 `splite_data.py` 的输出路径，例如 `r"D:\source\python\torch_big_data\data"`.
   - `target_root_dir = "./source_lajidata"`: 替换为实际的错误图像保存路径，如 `r"D:\source\python\torch_big_data\error_images"`.
   - `model_path = f"base_model_18_{learning_rate}_nolaji_source.pth"`: 确保保存路径有写入权限，可改为绝对路径，如 `r"D:\source\python\torch_big_data\models\base_model_18_{learning_rate}_nolaji_source.pth"`.
2. **参数**：
   - `num_classes = 4`: 确保与数据集的类别数一致（例如 `Cyclone`, `Wildfire`, `Flood`, `Earthquake`）。
   - `learning_rate = 0.1`: 学习率较高，可能导致训练不稳定，建议尝试 `0.01` 或 `0.001`。
   - `batch_size = 64`: 根据 GPU 内存调整，例如减少到 `32` 或 `16`。
   - `num_epochs = 25`: 可根据训练收敛情况调整。
3. **建议**：
   - 确保 `torchvision.models` 的 ResNet18 可用。
   - 检查数据集目录结构是否为 `data_dir/train/<category>` 和 `data_dir/val/<category>`。
   - 如果使用预训练模型，设置 `pretrained=True` 以提高性能。

---

#### 4. `base_achive.py`（多模型训练）

**功能**：

- 支持训练多个模型（ResNet18 和 ResNet34），分别使用不同学习率。
- 创建训练和验证数据加载器，加载指定数据集。
- 保存训练好的模型到 `models` 目录。

**执行方式**：

```bash
python base_achive.py
```

**文件之间的关系**：

- 与 `image_classification.py` 功能类似，但支持多模型训练。
- 依赖的数据集路径 `D:\source\python\MNIST_torch\deep_learn_class_devise\afhq` 可能与 `splite_data.py` 或 `file_image_source.py` 的输出不同。
- 保存的模型可能被 `image_prediction.py` 使用。

**需要修改的路径和参数**：

1. **路径**：
   - `data_dir = r"D:\source\python\MNIST_torch\deep_learn_class_devise\afhq"`: 替换为实际数据集路径，例如 `r"D:\source\python\torch_big_data\data"`.
   - `save_dir = "models"`: 改为绝对路径，如 `r"D:\source\python\torch_big_data\models"`.
2. **参数**：
   - `models_config = [{"name": "resnet18", "lr": 0.1}, {"name": "resnet34", "lr": 0.01}]`: 可调整学习率，例如将 ResNet18 的学习率改为 `0.01` 或 `0.001`。
   - `batch_size = 64`: 根据硬件性能调整。
   - `num_epochs = 10`: 可增加到 `25` 以匹配其他脚本。
3. **建议**：
   - 确保数据集路径与 `splite_data.py` 或 `file_image_source.py` 的输出一致。
   - 检查 `torchvision.models` 是否支持 ResNet18 和 ResNet34。
   - 考虑启用预训练模型（`pretrained=True`）以提高性能。

---

#### 5. `image_prediction.py`（模型预测）

**功能**：

- 加载预训练模型（默认 ResNet18）进行预测。
- 使用 `CustomImageFolder` 获取图像路径以记录预测错误的图像。
- 保存预测结果和错误图像路径到文件。

**执行方式**：

```bash
python image_prediction.py
```

**文件之间的关系**：

- 依赖 `image_classification.py` 或 `base_achive.py` 保存的模型文件。
- 使用 `./data_source2/val` 作为测试数据集，可能由 `file_image_source.py` 生成。
- 输出文件 `image_batch_results.txt` 和 `incorrect_images.txt` 用于分析预测结果。

**需要修改的路径和参数**：

1. **路径**：
   - `data_dir = "./data_source2"`: 替换为实际测试数据集路径，例如 `r"D:\source\python\torch_big_data\data_source2"`.
   - `model_path = r"D:\source\python\torch_big_data\data_vision\fuquqi_base_model_18_0.1_nolaji_source.pth"`: 替换为实际模型路径，例如 `r"D:\source\python\torch_big_data\models\base_model_18_0.1_nolaji_source.pth"`.
   - `output_file = "image_batch_results.txt"`: 可改为绝对路径，如 `r"D:\source\python\torch_big_data\results\image_batch_results.txt"`.
   - `incorrect_file = "./深度学习模型/incorrect_images.txt"`: 改为绝对路径，如 `r"D:\source\python\torch_big_data\results\incorrect_images.txt"`.
2. **参数**：
   - `batch_size = 64`: 根据硬件性能调整。
   - `label_map = {0: "Cyclone", 1: "Earthquake", 2: "Flood", 3: "Wildfire"}`: 确保与数据集的类别顺序一致。
3. **建议**：
   - 确保模型文件与训练脚本的输出一致。
   - 检查测试数据集目录结构是否为 `data_dir/val/<category>`。

---

#### 6. `file_image_source.py`（数据集分割）

**功能**：

- 与 `splite_data.py` 功能类似，将数据集按指定比例分割为训练集、验证集和测试集。
- 使用 `os` 模块操作文件系统，功能与 `splite_data.py` 略有重叠。

**执行方式**：

```bash
python file_image_source.py
```

**文件之间的关系**：

- 输出目录 `./data_source2` 被 `image_prediction.py` 使用。
- 源目录 `./Cyclone_Wildfire_Flood_Earthquake_Database` 可能与 `image_processing.py` 的输入路径相同。

**需要修改的路径和参数**：

1. **路径**：
   - `source_directory = "./Cyclone_Wildfire_Flood_Earthquake_Database"`: 替换为实际路径，例如 `r"D:\source\python\torch_big_data\Cyclone_Wildfire_Flood_Earthquake_Database"`.
   - `destination_directory = "./data_source2"`: 改为绝对路径，如 `r"D:\source\python\torch_big_data\data_source2"`.
2. **参数**：
   - `train_ratio = 0.7`, `val_ratio = 0.15`, `test_ratio = 0.15`: 确保比例之和为 1，可根据需求调整。
3. **建议**：
   - 如果 `splite_data.py` 已满足需求，可考虑删除此文件以避免功能重复。
   - 确保源目录包含按类别组织的部分目录的图像文件。

---

### 项目整体执行流程

1. **数据集分割**：
   - 运行 `splite_data.py` 或 `file_image_source.py` 将原始数据集分割为训练、验证和测试集。
   - 输出目录 `./data` 或 `./data_source2`。
2. **数据预处理**：
   - 运行 `image_processing.py` 对原始图像进行预处理，输出到指定目录（如 `./Wildfire`）。
3. **模型训练**：
   - 运行 `image_classification.py` 或 `base_achive.py` 训练 ResNet18 或 ResNet34 模型。
   - 使用分割后的 `./data/train` 和 `./data/val` 或 `./data_source2/train` 和 `./data_source2/val`。
   - 保存模型到指定路径。
4. **模型预测**：
   - 运行 `image_prediction.py` 使用训练好的模型进行预测。
   - 输出预测结果和错误图像路径。

### 统一路径配置建议

为了确保项目正常运行，建议统一所有文件的路径配置。假设数据集和输出目录位于 `D:\source\python\torch_big_data`，推荐以下路径设置：

- **源数据集**：`r"D:\source\python\torch_big_data\Cyclone_Wildfire_Flood_Earthquake_Database"`
- **分割数据集输出**：
  - `splite_data.py`: `r"D:\source\python\torch_big_data\data"`
  - `file_image_source.py`: `r"D:\source\python\torch_big_data\data_source2"`
- **预处理输出**：`r"D:\source\python\torch_big_data\processed_images"`
- **模型保存路径**：`r"D:\source\python\torch_big_data\models"`
- **错误图像路径**：`r"D:\source\python\torch_big_data\error_images"`
- **预测结果输出**：`r"D:\source\python\torch_big_data\results"`

### 其他建议

1. **环境依赖**：
   - 确保安装了必要的库：`torch`, `torchvision`, `numpy`, `opencv-python`, `pywt`, `pyspark`。
   - 如果使用 Spark，确保配置好 Spark 环境。
2. **类别一致性**：
   - 确保所有脚本中的类别数（`num_classes`）和类别映射（`label_map`）与数据集的实际类别一致。
3. **硬件优化**：
   - 根据 GPU/CPU 性能调整 `batch_size` 和 `num_epochs`。
   - 如果 GPU 内存不足，减少 `batch_size` 或使用 `torch.cuda.amp` 进行混合精度训练。
4. **调试**：
   - 在运行前，检查所有路径是否存在且有读写权限。
   - 启用日志记录以便调试，例如在 `image_processing.py` 中记录每个文件的处理状态。

通过以上修改，项目应能正常运行并完成从数据预处理到模型训练和预测的完整流程。
